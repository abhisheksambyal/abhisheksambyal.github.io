<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Google tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KEFJZWLLB5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-KEFJZWLLB5');
  </script>

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  
  <script type="text/javascript" src="js/hidebib.js"></script>

  <title>Abhishek Singh Sambyal</title>

  <meta name="Abhishek Singh Sambyal's Homepage" http-equiv="Content-Type" content="Abhishek Singh Sambyal's Homepage">
  <meta name="description" content="Abhishek's personal website with latest updates about his research.">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONTS -->
  <!-- <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
   -->
  <!-- Ubuntu Font -->
  <!-- <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@300;400;500;700&display=swap" rel="stylesheet"> -->

  <!-- ROBOTO Font -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@200..900&family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&family=Roboto+Mono:ital,wght@0,100..700;1,100..700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">




  <!-- JavaScript to scramble emails -->
  <script src="js/scramble.js"></script>

  <!-- Abhishek's Custom CSS -->
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="icon" type="image/png" href="images/title-icon.png">

</head>

<body>
  <div class="topbar">
    <ul class="nav fixed-top justify-content-center bg-dark">
      <li class="nav-item">
        <a class="nav-link" href="#introduction">Introduction</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#news">News</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#publications">Publications</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#ta">TA</a>
      </li>
      <li class="nav-item" >
        <a class="nav-link" href="resources.html">Resources</a>
      </li>
      <!-- <li class="nav-item" style="text-align: center;">
        <img src="images/halo-legendary-icon.png" width="32" height="32">
      </li> -->
    </ul>
  </div>
  <table
    style="width:100%;max-width:840px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- Introduction -->
          <!-- Introduction -->
          <!-- Introduction -->
          <!-- Introduction -->
          <!-- Introduction -->
          <!-- Introduction -->
          <table id="introduction">
            <tbody>
              <tr>
                <td>
                <!-- <img class="profileimage" alt="profile photo" src="images/abhishek1.jpg"> -->
                <img id="profileimage" alt="profile photo" src="images/abhishek1.jpg" style="float:left; margin-right: 20px; margin-bottom: 20px;" height="200px" class="profileimage">
                </td>
                <td>
                  <div>
                  <p>
                    <firstname>Abhishek </firstname><name>Singh Sambyal</name>
                    <br>
                    <b>email (academics): </b>
                    <font id="email-work" style="display:inline;">u.dautkedmapcs.hc@ <a href="#"
                        onclick="emailScramble.initAnimatedBubbleSort();return false;">unscramble</a></font>
                    <script>
                      emailScramble_work = new scrambledString(document.getElementById('email-work'),
                        'emailScramble_work', 'apii..i009riah.th10ckn@e1zscbrs',
                        [0, 23, 19, 3, 8, 25, 29, 16, 15, 10, 22, 20, 26, 2, 28, 21, 5, 17, 14, 27, 7, 30, 18, 6, 9, 13, 4, 11, 1, 24, 12]);
                    </script>
                    <br>
                    <b>email (personal): </b>
                    <font id="email-personal" style="display:inline;">u.dautkedmapcs.hc@ <a href="#"
                        onclick="emailScramble.initAnimatedBubbleSort();return false;">unscramble</a></font>
                    <script>
                      emailScramble_personal = new scrambledString(document.getElementById('email-personal'),
                        'emailScramble_personal', '.maoalg.siyabbahhik@cmmsle',
                        [22, 25, 0, 24, 19, 21, 17, 8, 4, 20, 13, 10, 1, 12, 14, 2, 5, 3, 7, 16, 23, 18, 11, 9, 15, 6]);
                    </script>
                  </p>
                  
                  <p class="text-justify">I am a PhD candidate in the department of Computer Science and Engineering</a> at the <a href="http://iitrpr.ac.in/" target="_blank">Indian Institute of Technology Ropar</a>,
                  India, where I am supervised by <a href="http://cse.iitrpr.ac.in/deepti/" target="_blank">Dr Deepti R Bathula</a> and <a href="https://seekayan.github.io/" target="_blank">Dr Narayanan C Krishnan</a>.
                  </p>

                  <p class="text-justify">My research interests lie in uncertainty quantification, confidence calibration and reliability of deep neural networks for medical imaging applications.</p>
                  <p>
                    <a href="https://www.dropbox.com/s/017yb1h95ano6v5/Resume_Abhishek_Singh_Sambyal.pdf?dl=0" class="boxed" target="_blank">CV</a>
                    <a href="https://github.com/abhisheksambyal" class="boxed" target="_blank">GitHub</a>
                    <a href="https://scholar.google.com/citations?user=FX5YpV8AAAAJ&hl=en" class="boxed" target="_blank">Google Scholar</a>
                    <a href="https://www.linkedin.com/in/abhishek-singh-sambyal/" class="boxed" target="_blank">LinkedIn</a>
                  </p>
                </div>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>
          <!-- News -->
          <!-- News -->
          <!-- News -->
          <!-- News -->
          <!-- News -->
          <!-- News -->
          <table id="news">
            <tbody>
              <tr>
                <td>
                  <heading>Recent News</heading>
                  <div style="line-height:60%;">
                    <br>
                  </div>
                </td>
              </tr>
              <tr>
                <td>
                  <ul>
                    <li><span class="badge bg-secondary">11 Aug 2024</span> Received <b>MICCAI 2024 RISE Registration Grant</b> for our paper. Thanks, <a href="https://miccai.org/" target="_blank">MICCAI Society</a>!</li>
                    <li><span class="badge bg-secondary">17 Jun 2024</span> Our work on <i>"LS+: Informed Label Smoothing for Improving Calibration in Medical Image Classification"</i> is accepted in <a href="https://conferences.miccai.org/2024/en/" target="_blank">MICCAI 2024.</a> Paper link will be added soon.
                    </li>
                    <li><span class="badge bg-secondary">27 Feb 2024</span> Our work on <i>"Mutually Exclusive Multi-Modal Approach for Parkinson's Disease Classification"</i> won the best student paper award in Bioimaging 2024.</a>
                    </li>
                    <li><span class="badge bg-secondary">02 Feb 2024</span> Our work on <i>"Wavelet-Based Feature Compression for Improved Knowledge Distillation"</i> is accepted in <a href="https://biomedicalimaging.org/2024/" target="_blank">ISBI 2024.</a>  Paper link will be added soon.
                    </li>
                    <li><span class="badge bg-secondary">22 Nov 2023</span> Our work on<i> "Leveraging Different Learning Styles for Improved Knowledge Distillation in Biomedical Imaging"</i> is accepted in Computers in Biology and Medicine <a href="https://www.sciencedirect.com/journal/computers-in-biology-and-medicine" target="_blank">(CBM)</a> journal.
                    </li>
                    <li><span class="badge bg-secondary">15 Sep 2023</span> Our work on<i> "Understanding Calibration of Deep Neural Networks for Medical Image Classification"</i> is accepted in Computer Methods and Programs in Biomedicine <a href="https://www.sciencedirect.com/journal/computer-methods-and-programs-in-biomedicine" target="_blank">(CMPB)</a> journal.
                    </li>
                    <a href="javascript:toggleblock('hiddennews')">---- more ----</a>
                    <div id="hiddennews" style="display: none;">
                      <li><span class="badge bg-secondary">27 Jul 2023</span> Presented our previous work<i> "A novel data augmentation approach to reducing aleatoric uncertainty in medical image analysis."</i> at India-Dalhousie Student Research Symposium: Addressing Common Challenges via Research & Innovation.
                      </li>
                      <li><span class="badge bg-secondary">24 Mar 2023</span> Presented our work<i> "Medical Image Analysis - Does Self-Supervised Learning Improve Calibration?"</i> at Bern Interpretable AI Symposium<a href="https://www.caim.unibe.ch/about_us/news_and_events/events_2022/bias_symposium/index_eng.html" target="_blank"> (BIAS)</a>, University of Bern.
                      </li>
                      <li><span class="badge bg-secondary">11 Feb 2022</span> Completed my thesis proposal seminar. I am now a PhD Candidate!</a>
                      </li>
                      <li><span class="badge bg-secondary">07 Jan 2022</span> Paper <i>"Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks"</i> accepted in <a href="https://biomedicalimaging.org/2022/" target="_blank">ISBI 2022.</a>
                      </li>
                      <li><span class="badge bg-secondary">18 Jul 2021</span> Attending International Conference on Machine Learning <a href="https://icml.cc/Conferences/2021" target="_blank">(ICML)</a> 2021 (Online).
                      </li>
                      <li><span class="badge bg-secondary">30 Sep 2020</span> Attending Medical Imaging MONAI Bootcamp 2020.</a>
                      </li>
                      <li><span class="badge bg-secondary">17 Aug 2020</span> Attending Oxford Machine Learning Summer School 2020<a href="https://www.oxfordml.school/oxml2020" target="_blank"> (OxML).</a>
                      </li>
                    </div>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>
          <!-- Publications -->
          <!-- Publications -->
          <!-- Publications -->
          <!-- Publications -->
          <!-- Publications -->
          <!-- Publications -->
          <table id="publications">
            <tbody>
              <!-- Heading -->
              <tr>
                <td>
                  <heading>Publications</heading>
                </td>
              </tr>
              </tbody>
          </table>
          <table id="publications" cellpadding="7">
            <tbody>
              <!-- Publication Entries -->
              <tr valign="top">
                <td width="20%"><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482523012295" target="_blank">
                <img src="images/cbm-2023.jpg" alt="cmpb2023" width="160" height="120" style="padding:10px;border-radius:15px;border:1px solid black">
                </a></td>
                <td width="80%">
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482523012295" target="_blank">
                    <papertitle>Leveraging Different Learning Styles for Improved Knowledge Distillation in Biomedical Imaging</papertitle>
                  </a>
                  <br>
                  Usma Niyaz, <strong>Abhishek Singh Sambyal</strong>, Deepti R. Bathula
                  <br>
                  <em>Computers in Biology and Medicine</em>, 2023
              
                  <div class="paperlinks" id="cbm-2023">
                  <a href="javascript:toggleblock('cbm-2023_abs')" class="boxed boxed_publication">abstract</a>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482523012295" class="boxed boxed_publication" target="_blank">journal</a>
                  <a href="https://arxiv.org/abs/2212.02931" class="boxed boxed_publication" target="_blank">arxiv</a>
                  <a shape="rect" href="javascript:togglebib('cbm-2023')" class="togglebib boxed boxed_publication">bibtex</a>
              
                  <p class="abstract_text" align="justify"> <span id="cbm-2023_abs" style="display: none;">Learning style refers to a type of training mechanism adopted by an individual to gain new knowledge. As suggested by the VARK model, humans have different learning preferences, like Visual (V), Auditory (A), Read/Write (R), and Kinesthetic (K), for acquiring and effectively processing information. Our work endeavors to leverage this concept of knowledge diversification to improve the performance of model compression techniques like Knowledge Distillation (KD) and Mutual Learning (ML). Consequently, we use a single-teacher and two-student network in a unified framework that not only allows for the transfer of knowledge from teacher to students (KD) but also encourages collaborative learning between students (ML). Unlike the conventional approach, where the teacher shares the same knowledge in the form of predictions or feature representations with the student network, our proposed approach employs a more diversified strategy by training one student with predictions and the other with feature maps from the teacher. We further extend this knowledge diversification by facilitating the exchange of predictions and feature maps between the two student networks, enriching their learning experiences. We have conducted comprehensive experiments with three benchmark datasets for both classification and segmentation tasks using two different network architecture combinations. These experimental results demonstrate that knowledge diversification in a combined KD and ML framework outperforms conventional KD or ML techniques (with similar network configuration) that only use predictions with an average improvement of 2%. Furthermore, consistent improvement in performance across different tasks, with various network architectures, and over state-of-the-art techniques establishes the robustness and generalizability of the proposed model.</span></p>
              
              <pre xml:space="preserve" class="bibtex_text" style="display: none;">
@article{NIYAZ-cbm-2023,
      title = {Leveraging different learning styles for improved knowledge distillation in biomedical imaging},
      journal = {Computers in Biology and Medicine},
      volume = {168},
      pages = {107764},
      year = {2024},
      issn = {0010-4825},
      doi = {https://doi.org/10.1016/j.compbiomed.2023.107764},
      author = {Usma Niyaz and Abhishek Singh Sambyal and Deepti R. Bathula},
}
              </pre>
                  </div>
                </td>
              </tr>

              <tr valign="top">
                <td width="20%"><a href="https://www.sciencedirect.com/science/article/abs/pii/S0169260723004820" target="_blank">
                <img src="images/cmpb-2023.png" alt="cmpb2023" width="160" height="120" style="padding:10px;border-radius:15px;border:1px solid black">
                </a></td>
                <td width="80%">
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169260723004820" target="_blank">
                    <papertitle>Understanding Calibration of Deep Neural Networks for Medical Image Classification</papertitle>
                  </a>
                  <br>
                  <strong>Abhishek Singh Sambyal</strong>, Usma Niyaz, Narayanan C. Krishnan, Deepti R. Bathula
                  <br>
                  <em>Computer Methods and Programs in Biomedicine</em>, 2023
              
                  <div class="paperlinks" id="cmpb-2023">
                  <a href="javascript:toggleblock('cmpb-2023_abs')" class="boxed boxed_publication">abstract</a>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169260723004820" class="boxed boxed_publication" target="_blank">journal</a>
                  <a href="https://arxiv.org/abs/2309.13132" class="boxed boxed_publication" target="_blank">arxiv</a>
                  <a shape="rect" href="javascript:togglebib('cmpb-2023')" class="togglebib boxed boxed_publication">bibtex</a>
              
                  <p class="abstract_text" align="justify"> <span id="cmpb-2023_abs" style="display: none;">In the field of medical image analysis, achieving high accuracy is not enough; ensuring well-calibrated predictions is also crucial. Confidence scores of a deep neural network play a pivotal role in explainability by providing insights into the model's certainty, identifying cases that require attention, and establishing trust in its predictions. Consequently, the significance of a well-calibrated model becomes paramount in the medical imaging domain, where accurate and reliable predictions are of utmost importance. While there has been a significant effort towards training modern deep neural networks to achieve high accuracy on medical imaging tasks, model calibration and factors that affect it remain under-explored. To address this, we conducted a comprehensive empirical study that explores model performance and calibration under different training regimes. We considered fully supervised training, which is the prevailing approach in the community, as well as rotation-based self-supervised method with and without transfer learning, across various datasets and architecture sizes. Multiple calibration metrics were employed to gain a holistic understanding of model calibration. Our study reveals that factors such as weight distributions and the similarity of learned representations correlate with the calibration trends observed in the models. Notably, models trained using rotation-based self-supervised pretrained regime exhibit significantly better calibration while achieving comparable or even superior performance compared to fully supervised models across different medical imaging datasets. These findings shed light on the importance of model calibration in medical image analysis and highlight the benefits of incorporating self-supervised learning approach to improve both performance and calibration.</span></p>
              
              <pre xml:space="preserve" class="bibtex_text" style="display: none;">
@article{understandingcalibration-2023,
      title = {Understanding calibration of deep neural networks for medical image classification},
      journal = {Computer Methods and Programs in Biomedicine},
      volume = {242},
      pages = {107816},
      year = {2023},
      issn = {0169-2607},
      doi = {https://doi.org/10.1016/j.cmpb.2023.107816},
      author = {Abhishek Singh Sambyal and Usma Niyaz and Narayanan C. Krishnan and Deepti R. Bathula},
  }
              </pre>
                  </div>
                </td>
              </tr>
              
              
              <tr valign="top">
                <td width="20%"><a href="https://ieeexplore.ieee.org/document/9761638" target="_blank">
                <!-- <img src="images/isbi2022.png" alt="isbi2022" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"> -->
                <img src="images/isbi2022.png" alt="isbi2022" width="160" height="120" style="padding:10px;border-radius:15px;border:1px solid black">
                </a></td>
                <td width="80%">
                  <a href="https://ieeexplore.ieee.org/document/9761638" target="_blank">
                    <papertitle>Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks</papertitle>
                  </a>
                  <br>
                  <strong>Abhishek Singh Sambyal</strong>, Narayanan C. Krishnan, Deepti R. Bathula
                  <br>
                  <em>IEEE 19th International Symposium on Biomedical Imaging (ISBI)</em>, 2022
              
                  <div class="paperlinks" id="trau">
                  <a href="javascript:toggleblock('whirl_abs')" class="boxed boxed_publication">abstract</a>
                  <a href="https://www.dropbox.com/s/rhekzgyf5o4p2lc/ISBI_Presentation.pdf?dl=0" class="boxed boxed_publication" target="_blank">presentation</a>
                  <a href="https://www.dropbox.com/s/5adrl9tyx6s67ii/Poster_ISBI_2022.pdf?dl=0" class="boxed boxed_publication" target="_blank">poster</a>
                  <a href="https://arxiv.org/abs/2110.11012" class="boxed boxed_publication" target="_blank">arxiv</a>
                  <a shape="rect" href="javascript:togglebib('trau')" class="togglebib boxed boxed_publication">bibtex</a>
              
                  <p class="abstract_text" align="justify"> <span id="whirl_abs" style="display: none;">In safety-critical applications like medical diagnosis, certainty associated with a model’s prediction is just as important as its accuracy. Consequently, uncertainty estimation and reduction play a crucial role. Uncertainty in predictions can be attributed to noise or randomness in data (aleatoric) and incorrect model inferences (epistemic). While model uncertainty can be reduced with more data or bigger models, aleatoric uncertainty is more intricate. This work proposes a novel approach that interprets data uncertainty estimated from a self-supervised task as noise inherent to the data and utilizes it to reduce aleatoric uncertainty in another task related to the same dataset via data augmentation. The proposed method was evaluated on a benchmark medical imaging dataset with image reconstruction as the self-supervised task and segmentation as the image analysis task. Our findings demonstrate the effectiveness of the proposed approach in significantly reducing the aleatoric uncertainty in the image segmentation task while achieving better or on-par performance compared to the standard augmentation techniques.</span></p>
              
              <pre xml:space="preserve" class="bibtex_text" style="display: none;">
@inproceedings{trau,
      title={Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks}, 
      author={Sambyal, Abhishek Singh and Krishnan, Narayanan C and Bathula, Deepti R},
      booktitle={2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)}, 
      year={2022},
      pages={1-4},
      doi={10.1109/ISBI52829.2022.9761638}
}
              </pre>
                  </div>
                </td>
              </tr>


              <tr valign="top">
                <td width="20%"><a href="https://ieeexplore.ieee.org/abstract/document/8745790" target="_blank">
                <!-- <img src="images/isbi2022.png" alt="isbi2022" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"> -->
                <img src="images/2018_advances.png" alt="adlt" width="160" height="120" style="padding:10px;border-radius:15px;border:1px solid black">
                </a></td>
                <td width="80%">
                  <a href="https://ieeexplore.ieee.org/abstract/document/8745790" target="_blank">
                    <papertitle>Advances in Deep Learning Techniques for Medical Image Analysis</papertitle>
                  </a>
                  <br>
                  Usma Niyaz, <strong>Abhishek Singh Sambyal</strong>, Devanand
                  <br>
                  <em>Fifth International Conference on Parallel, Distributed and Grid Computing (PDGC)</em>, 2018
              
                  <div class="paperlinks" id="adlt">
                  <a href="javascript:toggleblock('adlt_abs')" class="boxed boxed_publication">abstract</a>
                  <a shape="rect" href="javascript:togglebib('adlt')" class="togglebib boxed boxed_publication">bibtex</a>
              
                  <p class="abstract_text" align="justify"> <span id="adlt_abs" style="display: none;">Deep learning is contributing to the high level of services to the healthcare sector. As the digital medical data is increasing exponentially with time, early detection and prediction of diseases are becoming more efficient because of the deep learning techniques which reduce the fatality rate to a great extent. The main focus of this paper is to provide the comprehensive review of deep learning in the domain of medical image processing and analysis. We have demonstrated the use of new deep learning architectures in oncology for the prediction of different types of cancer like the brain, lung, skin, etc. The state-of-the-art architectures effectively carry out analysis of 2D and 3D medical images to make the diagnosis of patients faster and more accurate. The use of popular approaches in machine learning such as ensemble and transfer learning with fine-tuning of parameters improve the performance of the deep neural networks in medical image analysis. The existing deep networks urge the new image classification network called Capsule Network (CapsNet) to make the classification and detection comparatively better. The equivariance characteristics of CapsNet make it more influential as it discourages the effect of any structural invariance of an input image on the network.</span></p>
              
              <pre xml:space="preserve" class="bibtex_text" style="display: none;">
@inproceedings{adlt,
      title={Advances in Deep Learning Techniques for Medical Image Analysis}, 
      author={Niyaz, Usma and Sambyal, Abhishek Singh and Devanand},
      booktitle={2018 Fifth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
      year={2018},
      doi={10.1109/PDGC.2018.8745790}
}
              </pre>
                  </div>
                </td>
              </tr>


              <tr valign="top">
                <td width="20%"><a href="https://link.springer.com/chapter/10.1007/978-981-15-0035-0_6" target="_blank">
                <!-- <img src="images/isbi2022.png" alt="isbi2022" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"> -->
                <img src="images/2018_evaluation.png" alt="osm" width="160" height="120" style="padding:10px;border-radius:15px;border:1px solid black">
                </a></td>
                <td width="80%">
                  <a href="https://link.springer.com/chapter/10.1007/978-981-15-0035-0_6" target="_blank">
                    <papertitle>Evaluation of Deep Learning Model with Optimizing and Satisficing Metrics for Lung
                      Segmentation</papertitle>
                  </a>
                  <br>
                  Usma Niyaz, <strong>Abhishek Singh Sambyal</strong>, Devanand
                  <br>
                  <em>Soft Computing for Problem Solving (SocProS)[Proceedings in AISC]</em>, 2018
              
                  <div class="paperlinks" id="osm">
                  <a href="javascript:toggleblock('osm_abs')" class="boxed boxed_publication">abstract</a>
                  <a shape="rect" href="javascript:togglebib('osm')" class="togglebib boxed boxed_publication">bibtex</a>
              
                  <p class="abstract_text" align="justify"> <span id="osm_abs" style="display: none;">The segmentation in medical image analysis is a crucial and prerequisite process during the diagnosis of the diseases. The need for segmentation is important to attain the region of interest where the probability of occurrence of an abnormality such as a nodule in the lungs or tumor in the brain is high. In this paper, we have proposed a new architecture called FS-Net which is a convolutional neural network- based model for the segmentation of lungs in CT scan images. It performs encoding of images into the feature maps and then decodes the feature maps into their respective lung masks. We have also trained the state-of-the-art U-Net on the same dataset and compared the results on the basis of optimizing and satisficing metrics. These metrics are useful for the selection of a better model with the maximum score at the satisfying condition. The FS-Net is computationally very efficient and achieves promising dice coefficient and loss score when compared with the U-Net taking one-third of the time.</span></p>
              
              <pre xml:space="preserve" class="bibtex_text" style="display: none;">
@inproceedings{osm,
      title={Evaluation of Deep Learning Model with Optimizing  and Satisficing Metrics for Lung Segmentation},
      author={Niyaz, Usma and Sambyal, Abhishek Singh and Padha, Devanand},
      booktitle={Soft Computing for Problem Solving},
      year={2020}
}
              </pre>
                  </div>
                </td>
              </tr>


              <tr valign="top">
                <td width="20%"><a href="https://ieeexplore.ieee.org/abstract/document/7915086" target="_blank">
                <!-- <img src="images/isbi2022.png" alt="isbi2022" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"> -->
                <img src="images/2016_knowledge.png" alt="knowabs" width="160" height="120" style="padding:10px;border-radius:15px;border:1px solid black">
                </a></td>
                <td width="80%">
                  <a href="https://ieeexplore.ieee.org/abstract/document/7915086" target="_blank">
                    <papertitle>Knowledge abstraction from textural features of brain MRI images for diagnosing brain tumor
                      using statistical techniques and associative classification</papertitle>
                  </a>
                  <br>
                  <strong>Abhishek Singh Sambyal</strong>, Asha T.
                  <br>
                  <em>International Conference on Systems in Medicine and Biology (ICSMB)</em>, 2016
              
                  <div class="paperlinks" id="knowabs">
                  <a href="javascript:toggleblock('knowabs_abs')" class="boxed boxed_publication">abstract</a>
                  <a shape="rect" href="javascript:togglebib('knowabs')" class="togglebib boxed boxed_publication">bibtex</a>
                  <a href="https://github.com/abhisheksambyal/Disease-Detection-using-image-processing-and-data-mining" class="boxed boxed_publication" target="_blank">code</a>
              
                  <p class="abstract_text" align="justify"> <span id="knowabs_abs" style="display: none;">This paper presents a methodology for finding the association rules using associative classification which can be used to abstract knowledge from brain MRI images. Reducing the size of images using different thresholds help to reduce the complexity of the proposed system without affecting the correctness of these images. Textural features are taken into consideration because when there is a wide variation of features of discrete gray tone, the texture dominates more. Gray-Tone Spatial-Dependence matrices are calculated from images in which textural information is contained. The system uses a supervised learning approach for selecting the important features from different textural features. Using associative classification, the rules are generated from selected textural features which abstract the knowledge from the images.</span></p>
              
              <pre xml:space="preserve" class="bibtex_text" style="display: none;">
@inproceedings{knowabs,
      title={Knowledge abstraction from textural features of brain MRI images for diagnosing brain tumor using 
      statistical techniques and associative classification}, 
      author={Sambyal, Abhishek Singh and Asha, T.},
      booktitle={2016 International Conference on Systems in Medicine and Biology (ICSMB)}, 
      year={2016},
      doi={10.1109/ICSMB.2016.7915086}
}
              </pre>
                  </div>
                </td>
              </tr>


            </tbody>
          </table>
          <hr>

                    <!-- Academic Service Section -->
          <!-- Academic Service Section -->
          <!-- Academic Service Section -->
          <!-- Academic Service Section -->
          <!-- Academic Service Section -->
          <!-- Academic Service Section -->
          <table id="academicservice">
            <tbody>
              <tr>
                <td>
                  <heading>Academic Service</heading>
                  <div style="line-height:60%;">
                    <br>
                  </div>
                  <!-- I regularly serve as reviewers for following conferences and journals. -->
                  <ul>
                    <li>
                      Reviewer: <a href="https://conferences.miccai.org/2024/en/" target="_blank">MICCAI 2024</a>.
                    </li>
                    <!-- <li>
                      Journal: Computer Methods and Program in Biomedicine.
                    </li> -->
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>

          <!-- Teaching Assistant Section -->
          <!-- Teaching Assistant Section -->
          <!-- Teaching Assistant Section -->
          <!-- Teaching Assistant Section -->
          <!-- Teaching Assistant Section -->
          <!-- Teaching Assistant Section -->
          <table id="ta">
            <tbody>
              <tr>
                <td>
                  <heading>Teaching</heading>
                  <div style="line-height:60%;">
                    <br>
                  </div>
                </td>
              </tr>
              <tr>
                <td>
                  <ul>
                    <li> <strong>Digital Image Processing & Analysis (CS517),</strong> Autumn Semester 2021, 2022
                      <br>
                      Teaching Assistant with <a href="http://cse.iitrpr.ac.in/deepti/" target="_blank">Dr Deepti R Bathula</a>
                    </li>
                    <p></p>
                    <li> <strong>Computer Vision (CS518),</strong> Autumn Semester 2020
                      <br>
                      Teaching Assistant with <a href="https://sites.google.com/site/raamsubram/" target="_blank">Dr Ramanathan Subramanian</a>
                    </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>

          <!-- Template Credit section -->
          <!-- Template Credit section -->
          <!-- Template Credit section -->
          <!-- Template Credit section -->
          <!-- Template Credit section -->
          <!-- Template Credit section -->
          <div id="template-reference" align="right"><p>Template from <a href="http://www.cs.berkeley.edu/~barron/" target="_blank">1</a>,<a href="https://www.cs.cmu.edu/~dpathak/" target="_blank">2</a> and <a href="http://jeffdonahue.com/" target="_blank">3</a></p>
          </div>
        </td>
      </tr>
    </tbody>
  </table>
  
  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td>
          <p align="right">
            <font size="1.5">
              Template from <a href="http://www.cs.berkeley.edu/~barron/">this</a>,<a
                href="https://www.cs.cmu.edu/~dpathak/">this</a> and <a href="http://jeffdonahue.com/">this</a>
            </font>
          </p>
        </td>
      </tr>
    </tbody>
  </table> -->

  <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
  <script>
    AOS.init();
  </script>
</body>

</html>
